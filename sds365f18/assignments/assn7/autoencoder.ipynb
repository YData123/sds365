{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetID: !! ADD NET_ID !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "This code includes implementations of various simple autoencoders using the Keras front end to TensorFlow.\n",
    "You should first run all of the code on the MNIST data, and gain a basic understanding of what everything is doing. \n",
    "Then, carry out the simple experiments described in Problem 2 of the assignment. For 2(b) (10 points), you need to run everything on the Fashion MNIST data and fill in the cells marked _your documentation/description goes here_ with documentation of the code or descriptions of the results. You should also include more plots of images and weights, as described in the assignment writeup. For 2(c) (10 points) you will fit a series of networks, varying the dimension of the bottleneck.\n",
    "\n",
    "The starter code for this assignment is from [https://github.com/ardendertat/Applied-Deep-Learning-with-Keras](https://github.com/ardendertat/Applied-Deep-Learning-with-Keras). For Keras documentation, see [https://keras.io](https://keras.io).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.regularizers import l1\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "_[your documentation goes here]_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autoencoder_outputs(autoencoder, n, dims):\n",
    "    decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "    # number of example digits to show\n",
    "    plt.figure(figsize=(2*n, 4.5))\n",
    "    for i in range(n):\n",
    "        # plot original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Original Images')\n",
    "\n",
    "        # plot reconstruction \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Reconstructed Images')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "_[your documentation goes here]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow autoencoder\n",
    "_[your documentation goes here]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "code_size = 32\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "code = Dense(code_size, activation='relu')(input_img)\n",
    "output_img = Dense(input_size, activation='sigmoid')(code)\n",
    "\n",
    "autoencoder = Model(input_img, output_img)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autoencoder_outputs(autoencoder, 30, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = autoencoder.get_weights()[0].T\n",
    "\n",
    "n = 30\n",
    "plt.figure(figsize=(n*2, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(weights[i+0].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of above results\n",
    "_[your description goes here]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoder\n",
    "_[your documentation goes here]_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 128\n",
    "code_size = 32\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "code = Dense(code_size, activation='relu')(hidden_1)\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "autoencoder = Model(input_img, output_img)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autoencoder_outputs(autoencoder, 10, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = autoencoder.get_weights()[0].T\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(weights[i+0].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of above results\n",
    "_[your description goes here]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Denoising autoencoder\n",
    "_[your documentation goes here]_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.20\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0.0, 1.0)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0.0, 1.0)\n",
    "\n",
    "n = 5\n",
    "plt.figure(figsize=(10, 4.5))\n",
    "for i in range(n):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n/2:\n",
    "        ax.set_title('Original Images')\n",
    "\n",
    "    # plot noisy image \n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n/2:\n",
    "        ax.set_title('Noisy Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 128\n",
    "code_size = 32\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "code = Dense(code_size, activation='relu')(hidden_1)\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "autoencoder = Model(input_img, output_img)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_noisy, x_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "images = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "for i in range(n):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n/2:\n",
    "        ax.set_title('Original Images')\n",
    "\n",
    "    # plot noisy image \n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n/2:\n",
    "        ax.set_title('Noisy Input')\n",
    "        \n",
    "    # plot noisy image \n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(images[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n/2:\n",
    "        ax.set_title('Autoencoder Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = autoencoder.get_weights()[0].T\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(weights[i+0].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of above results\n",
    "_[your description goes here]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sparse autoencoders\n",
    "_[your documentation goes here]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 128\n",
    "code_size = 32\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "code = Dense(code_size, activation='relu')(hidden_1)\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "autoencoder_standard = Model(input_img, output_img)\n",
    "autoencoder_standard.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history_standard = autoencoder_standard.fit(x_train, x_train, epochs=20)\n",
    "\n",
    "encoded_standard = Model(input_img, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autoencoder_outputs(autoencoder_standard, 10, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = autoencoder_standard.get_weights()[0].T\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(n*2, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(weights[i].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 128\n",
    "code_size = 32\n",
    "\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='relu', activity_regularizer=l1(10e-6))(input_img)\n",
    "code = Dense(code_size, activation='relu', activity_regularizer=l1(10e-6))(hidden_1)\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "autoencoder_regularized = Model(input_img, output_img)\n",
    "autoencoder_regularized.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history_regularized = autoencoder_regularized.fit(x_train, x_train, epochs=20)\n",
    "\n",
    "encoded_regularized = Model(input_img, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_autoencoder_outputs(autoencoder_regularized, 10, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = autoencoder_regularized.get_weights()[0].T\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(2*n, 5))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(weights[i].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of above results\n",
    "_[your description goes here]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "_[your documentation goes here]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_standard.evaluate(x_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_regularized.evaluate(x_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_standard.predict(x_test).mean())\n",
    "print(encoded_regularized.predict(x_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a series of shallow networks of varying complexity (10 points)\n",
    "\n",
    "Your final task is to train a sequence of shallow networks, varying the code size parameter.\n",
    "Plot the training error and test error as a function of the code size. Describing your findings. Interpret them in terms of the bias/variance tradeoff. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
